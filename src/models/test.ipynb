{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6ae11b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import math\n",
    "import pywt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b58814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbecf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multimodal_multiscale_wavelet_align(image_embedding, text_embedding):\n",
    "    '''\n",
    "    Desc: 多模态多尺度小波变换对齐\n",
    "    Args:\n",
    "        image_embedding: 图像embedding, image_embedding.shape: torch.Size([7050, 64]) \n",
    "        text_embedding: 文本embedding, text_embedding.shape: torch.Size([7050, 64]), 7050个物品,每个物品编码为64维向量\n",
    "    Function:\n",
    "        对图像和文本嵌入进行多模态多尺度小波变换对齐 ：\n",
    "        Steps1: 选取模态领域适应的合适小波基['harr', 'db1-20', 'bior1.3'], 选择高通滤波器的下采样分级尺度level,本文默认选择level3, 注意输入的特征向量是一维度，因此暂时不考虑水平、垂直、对角。\n",
    "        Steps2: Multimodal Wavelet Transform Learning Project： 获取图像模态特征的image_coeffs（一个低通分量，三个高通分量）；文本模态特征的text_coeffs（一个低通分量，三个高通分量）\n",
    "        Steps3: 多模态多尺度频域空间对齐 Multimodal Multi-Scale Frequency Domain Align：\n",
    "                3.1低频信号对齐\n",
    "                    1.对于低频信号（第 3 级水平低频分量），首先对图像模态和文本模态下的低频信号分别进行LoRA(奇异值分解（SVD）),用于去除冗余信息，保留主要特征。 \n",
    "                    2.然后,再分别对进行归一化，对图像低频信号，可将其像素值归一化到特定范围，如 [0, 1] 或 [-1, 1]，以消除不同图像之间的亮度差异等影响。 对于文本低频信号，可对词向量或特征向量进行归一化，使不同文本的特征具有可比性，例如采用 L2 归一化。\n",
    "                    3.然后再将LoRa和归一化后的两个模态的特征向量进行对齐，对齐方式采用语义注意力机制， 生成一个新的融合模态第 3 级水平低频分量\n",
    "                3.2 高频信号多尺度对齐 TODO：高频信号不同等级能量是否才用不同对齐方式？\n",
    "                    1.对图像和文本的第 3 级水平高频分量进行对齐，对齐方式采用频域能量对齐，生成一个新的融合模态第 3 级水平高频分量\n",
    "                    2.对图像和文本的第 2 级水平高频分量进行对齐， 生成一个新的融合模态第 2 级水平高频分量\n",
    "                    3.对图像和文本的第 1 级水平高频分量分别先进行去噪，再进行对齐， 生成一个新的融合模态第 1 级水平高频分量\n",
    "        Steps4： Multimodal Wavelet Inverse Transform 多模态小波重建\n",
    "\n",
    "                对融合模态的低频分量和3个高频分量进行小波逆变换，重建为一个多模态频域对齐以及语义域融合的特征向量fusion_wave\n",
    "                对图像模态、文本模态经过上述变换后，进行小波逆变换，重建为新的图像image_embedding_wave、文本模态特征向量text_embedding_wave。\n",
    "    Returns:\n",
    "        image_embedding_wave.shape: torch.Size([7050, 64]) text_embedding_wave.shape: torch.Size([7050, 64]) fusion_wave.shape: torch.Size([7050, 64])\n",
    "    '''\n",
    "    device = image_embedding.device\n",
    "    print(\"device:\", device)\n",
    "    # print(\"image_embedding:\", image_embedding.shape)\n",
    "    # 转换为numpy数组进行小波变换\n",
    "    # image_np = image_embedding.detach().cpu().numpy()\n",
    "    # text_np = text_embedding.detach().cpu().numpy()\n",
    "\n",
    "    # 定义小波类型\n",
    "    wavelet = 'db4'\n",
    "    level = 3 \n",
    "\n",
    "    # 对图像和文本嵌入进行小波变换\n",
    "    '''\n",
    "    原始信号 如果输入是 (256, 256) 的图像，axis=1（水平方向分解），level=3：\n",
    "│\n",
    "    ├── cA3（最低频，最模糊的近似）      主体信号，轮廓 （保留）  (256, 32)  第 3 级水平低频分量\n",
    "    │\n",
    "    ├── cD3（第3级细节，较大尺度的高频） 大尺度边缘 最精细的细节信息 (256, 32) 第 3 级水平高频分量\n",
    "    │\n",
    "    ├── cD2（第2级细节，中等尺度的高频） 中尺度细节，更细微的边缘和纹理变化 (256, 64) 第 2 级水平高频分量\n",
    "    │\n",
    "    └── cD1（第1级细节，最细尺度的高频） 高频噪声->去噪 (256, 128) 第 1 级水平高频分量\n",
    "    '''\n",
    "    image_coeffs = wavelet_decompose(image_embedding, wavelet, level=level, axis=1, device=device)\n",
    "    text_coeffs = wavelet_decompose(text_embedding, wavelet, level=level, axis=1, device=device)\n",
    "\n",
    "    '''\n",
    "    image_coeffs shapes:\n",
    "        wavelet_decompose Level 4: (7050, 14)\n",
    "        wavelet_decompose Level 3: (7050, 14)\n",
    "        wavelet_decompose Level 2: (7050, 21)\n",
    "        wavelet_decompose Level 1: (7050, 35)\n",
    "    text_coeffs shapes:\n",
    "        wavelet_decompose Level 4: (7050, 14)\n",
    "        wavelet_decompose Level 3: (7050, 14)\n",
    "        wavelet_decompose Level 2: (7050, 21)\n",
    "        wavelet_decompose Level 1: (7050, 35)\n",
    "    '''\n",
    "    # len(image_coeffs): 4 len(text_coeffs): 4\n",
    "    # print(\"len(image_coeffs):\", len(image_coeffs), \"len(text_coeffs):\", len(text_coeffs))\n",
    "    # 对每一级系数进行对齐和融合\n",
    "    # ===================== 多模态多尺度频域对齐 =====================\n",
    "    fused_coeffs = []\n",
    "    img_coeffs_proc = []\n",
    "    txt_coeffs_proc = []\n",
    "\n",
    "    for i, (img_coeff, txt_coeff) in enumerate(zip(image_coeffs, text_coeffs)):        \n",
    "        # 低频分量\n",
    "        if i == 0: \n",
    "            img_proc = process_low(img_coeff, modality='image')\n",
    "            txt_proc = process_low(txt_coeff, modality='text')\n",
    "            # 融合\n",
    "            fused = fuse_low(img_proc, txt_proc)\n",
    "        # 高频分量\n",
    "        else:       \n",
    "            level_type = len(image_coeffs)-i  # 计算当前层级(3,2,1)\n",
    "            # 直接传递原始系数用于重建\n",
    "            img_proc = img_coeff  \n",
    "            txt_proc = txt_coeff\n",
    "            # 融合处理\n",
    "            fused = fuse_high(img_coeff, txt_coeff, level_type)\n",
    "        # 保存处理结果\n",
    "        img_coeffs_proc.append(img_proc)\n",
    "        txt_coeffs_proc.append(txt_proc)\n",
    "        fused_coeffs.append(fused)\n",
    "\n",
    "\n",
    "    # 进行小波逆变换\n",
    "    image_embedding_wave = wavelet_reconstruct(img_coeffs_proc, wavelet, axis=1, device=device)\n",
    "    text_embedding_wave = wavelet_reconstruct(txt_coeffs_proc, wavelet, axis=1, device=device)\n",
    "    fusion_wave = wavelet_reconstruct(fused_coeffs, wavelet, axis=1, device=device)\n",
    "\n",
    "    return image_embedding_wave, text_embedding_wave, fusion_wave\n",
    "\n",
    "def wavelet_decompose(x, wavelet='db4', level=3, axis=1, device='cuda'):\n",
    "    '''\n",
    "        小波变换分解\n",
    "        Steps1: 选取模态领域适应的合适小波基['harr', 'db1-20', 'bior1.3'], 选择高通滤波器的下采样分级尺度level,本文默认选择level3, 注意输入的特征向量是一维度，因此暂时不考虑水平、垂直、对角。\n",
    "\n",
    "    '''\n",
    "    x_np = x.detach().cpu().numpy()\n",
    "    coeffs = pywt.wavedec(x_np, wavelet, level=level, axis=axis)\n",
    "    return [torch.tensor(c, device=device, dtype=torch.float32) for c in coeffs]\n",
    "    # return pywt.wavedec(x, wavelet, level=level, axis=axis)\n",
    "\n",
    "    # ===================== 小波重建 =====================\n",
    "def wavelet_reconstruct(coeffs, wavelet='db4', axis=1, device='cuda'):\n",
    "    coeffs_np = [c.detach().cpu().numpy() for c in coeffs]\n",
    "    rec = pywt.waverec(coeffs_np, wavelet, axis=1)\n",
    "    return torch.tensor(rec, device=device, dtype=torch.float32)\n",
    "\n",
    "def process_low(coeff, modality='image'):\n",
    "    \"\"\"\n",
    "        低频信号: SVD降维+归一化\n",
    "    \n",
    "    \"\"\"\n",
    "    # SVD降维\n",
    "    U, S, V = torch.svd_lowrank(coeff, q=min(coeff.shape)//2)\n",
    "    recon = U @ torch.diag(S) @ V.T\n",
    "\n",
    "    # 归一化\n",
    "    if modality == 'image':\n",
    "        recon = 2 * (recon - recon.min())/(recon.max() - recon.min() + 1e-8) - 1\n",
    "    else:\n",
    "        recon = torch.nn.functional.normalize(recon, p=2, dim=1)\n",
    "    return recon\n",
    "\n",
    "\n",
    "def fuse_low(img_low, txt_low):\n",
    "    \"\"\"\n",
    "        低频信号对齐: 基于语义的attention\n",
    "    \"\"\"\n",
    "    # 语义注意力机制\n",
    "    attn = torch.stack([img_low, txt_low], dim=1)  # [N, 2, D]\n",
    "    attn_weights = torch.softmax(attn @ attn.transpose(1, 2), dim=1)  # [N, 2, 2]\n",
    "    # 加权融合\n",
    "    w_img = attn_weights[:, 0, 0].unsqueeze(1)\n",
    "    w_txt = attn_weights[:, 0, 1].unsqueeze(1)\n",
    "    return w_img * img_low + w_txt * txt_low\n",
    "\n",
    "\n",
    "def fuse_high(img_high, txt_high, level_type):\n",
    "    \"\"\"\n",
    "        低频信号对齐: 基于语义的attention\n",
    "    \"\"\"\n",
    "    eps = 1e-8  # 防止除以零\n",
    "    \n",
    "    if level_type == 3:  # 能量对齐\n",
    "        energy_img = torch.norm(img_high, dim=1, keepdim=True)\n",
    "        energy_txt = torch.norm(txt_high, dim=1, keepdim=True)\n",
    "        return (energy_img*img_high + energy_txt*txt_high)/(energy_img + energy_txt + eps)\n",
    "        \n",
    "    elif level_type == 2:  # 直接平均\n",
    "        return (img_high + txt_high) / 2\n",
    "        \n",
    "    elif level_type == 1:  # 去噪后融合\n",
    "        def denoise(x):\n",
    "            threshold = torch.median(torch.abs(x)) / 0.6745\n",
    "            return torch.sign(x) * torch.relu(torch.abs(x) - threshold)\n",
    "            \n",
    "        return (denoise(img_high) + denoise(txt_high)) / 2\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0c7d4538",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.randn(7050, 64).cuda()\n",
    "txt = torch.randn(7050, 64).cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "53717999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n",
      "图像重建特征形状: torch.Size([7050, 64])\n",
      "文本重建特征形状: torch.Size([7050, 64])\n",
      "融合特征形状: torch.Size([7050, 64])\n"
     ]
    }
   ],
   "source": [
    "img_wave, txt_wave, fusion = multimodal_multiscale_wavelet_align(img, txt)\n",
    "\n",
    "print(\"图像重建特征形状:\", img_wave.shape)    # [7050,64]\n",
    "print(\"文本重建特征形状:\", txt_wave.shape)    # [7050,64]\n",
    "print(\"融合特征形状:\", fusion.shape)        # [7050,64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4700df05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bfed4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pytorch_wavelets import DWT1DForward, DWT1DInverse\n",
    "\n",
    "class MultiModalWaveletInterestAttention(nn.Module):\n",
    "    '''\n",
    "    多模态小波兴趣注意力机制（门控融合+对比学习）\n",
    "    '''\n",
    "    def __init__(self, \n",
    "                 embed_dim, \n",
    "                 wavelet_name='db4', \n",
    "                 contrastive_temperature=0.5):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.contrastive_temperature = contrastive_temperature\n",
    "        \n",
    "        # ------------------- 小波变换 -------------------\n",
    "        self.dwt = DWT1DForward(wave=wavelet_name, J=1)  # 固定1级分解（低频+高频）\n",
    "        self.idwt = DWT1DInverse(wave=wavelet_name)\n",
    "        \n",
    "        # ------------------- 门控融合组件 -------------------\n",
    "        # 低频门控（融合content/side/fusion三模态低频）\n",
    "        self.low_gate = nn.Sequential(\n",
    "            nn.Linear(3 * (embed_dim//2), 3),  # 输入3个低频特征（每个dim=embed_dim//2）\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "        # 高频门控（融合三模态高频）\n",
    "        self.high_gate = nn.Sequential(\n",
    "            nn.Linear(3 * (embed_dim//2), 3),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "        \n",
    "        # ------------------- 频域投影 -------------------\n",
    "        self.low_proj = nn.Linear(embed_dim//2, embed_dim)  # 低频恢复原始维度\n",
    "        self.high_proj = nn.Linear(embed_dim//2, embed_dim)  # 高频恢复原始维度\n",
    "        \n",
    "        # ------------------- 动态注意力 -------------------\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(2 * embed_dim, embed_dim//4),  # 输入：低频+高频投影后的特征\n",
    "            nn.LayerNorm(embed_dim//4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(embed_dim//4, 2),  # 输出低频和高频权重\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "        \n",
    "        # ------------------- 对比学习头 -------------------\n",
    "        self.low_contrast = nn.Sequential(\n",
    "            nn.Linear(embed_dim//2, embed_dim//2),\n",
    "            nn.LayerNorm(embed_dim//2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.high_contrast = nn.Sequential(\n",
    "            nn.Linear(embed_dim//2, embed_dim//2),\n",
    "            nn.LayerNorm(embed_dim//2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # ------------------- 残差连接 -------------------\n",
    "        self.res_norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def wavelet_decomp(self, x):\n",
    "        \"\"\"单级小波分解：返回低频和高频\"\"\"\n",
    "        x = x.unsqueeze(1)  # [B,1,D]\n",
    "        cA, cD = self.dwt(x)\n",
    "        return cA.squeeze(1), cD[0].squeeze(1)  # [B,D/2], [B,D/2]\n",
    "\n",
    "    def gated_fusion(self, inputs, gate):\n",
    "        \"\"\"通用门控融合函数\"\"\"\n",
    "        # inputs shape: [B, 3, D/2]（3个模态：content/side/fusion）\n",
    "        weights = gate(inputs.reshape(-1, 3 * (self.embed_dim//2)))  # [B*3, 3] → [B,3,3]\n",
    "        weights = weights.softmax(dim=-1).unsqueeze(-1)  # [B,3,3,1]\n",
    "        fused = torch.sum(inputs * weights, dim=1)  # 加权求和 → [B, D/2]\n",
    "        return fused\n",
    "\n",
    "    def forward(self, content_embeds, side_embeds, labels=None):\n",
    "        B = content_embeds.shape[0]\n",
    "        fusion_embeds = content_embeds + side_embeds  # 基础融合特征\n",
    "        \n",
    "        # ------------------- 1. 小波分解 -------------------\n",
    "        # 分解三模态特征\n",
    "        c_low, c_high = self.wavelet_decomp(content_embeds)\n",
    "        s_low, s_high = self.wavelet_decomp(side_embeds)\n",
    "        f_low, f_high = self.wavelet_decomp(fusion_embeds)\n",
    "        \n",
    "        # ------------------- 2. 门控融合低频和高频 -------------------\n",
    "        # 拼接三模态特征为 [B,3,D/2]\n",
    "        low_input = torch.stack([c_low, s_low, f_low], dim=1)  # [B,3,D/2]\n",
    "        print(\"low_input.shape:\", low_input.shape)\n",
    "        high_input = torch.stack([c_high, s_high, f_high], dim=1)  # [B,3,D/2]\n",
    "        \n",
    "        # 门控融合\n",
    "        low_fused = self.gated_fusion(low_input, self.low_gate)  # [B,D/2]\n",
    "        high_fused = self.gated_fusion(high_input, self.high_gate)  # [B,D/2]\n",
    "        \n",
    "        # ------------------- 3. 频域特征投影回原始维度 -------------------\n",
    "        low_proj = self.low_proj(low_fused)  # [B,D/2] → [B,D]\n",
    "        high_proj = self.high_proj(high_fused)  # [B,D/2] → [B,D]\n",
    "        \n",
    "        # ------------------- 4. 动态频域注意力 -------------------\n",
    "        attn_input = torch.cat([low_proj, high_proj], dim=-1)  # [B, 2D]\n",
    "        weights = self.attention(attn_input)  # [B,2]：[low_weight, high_weight]\n",
    "        final_embedding = weights[:,0:1] * low_proj + weights[:,1:2] * high_proj\n",
    "        \n",
    "        # ------------------- 5. 残差连接 -------------------\n",
    "        residual = self.res_norm(fusion_embeds)  # 归一化原始融合特征\n",
    "        output = final_embedding + residual  # 残差连接\n",
    "        \n",
    "        # ------------------- 6. 对比学习（可选） -------------------\n",
    "        contrastive_loss = None\n",
    "        if labels is not None and self.training:\n",
    "            contrastive_loss = self.compute_contrastive_loss(\n",
    "                low_fused, high_fused, labels\n",
    "            )\n",
    "        \n",
    "        return output, low_fused, high_fused, contrastive_loss\n",
    "\n",
    "    def compute_contrastive_loss(self, low_fused, high_fused, labels):\n",
    "        \"\"\"计算低频（热门）和高频（小众）的对比损失\"\"\"\n",
    "        # 低频对比：同类样本低频应相似\n",
    "        low_repr = F.normalize(self.low_contrast(low_fused), dim=-1)  # [B, D/2]\n",
    "        low_sim = torch.matmul(low_repr, low_repr.T) / self.contrastive_temperature\n",
    "        \n",
    "        # 高频对比：同类样本高频应差异大\n",
    "        high_repr = F.normalize(self.high_contrast(high_fused), dim=-1)  # [B, D/2]\n",
    "        high_sim = torch.matmul(high_repr, high_repr.T) / self.contrastive_temperature\n",
    "        \n",
    "        # 正负样本掩码\n",
    "        pos_mask = (labels.unsqueeze(1) == labels.unsqueeze(0)).float()\n",
    "        neg_mask = 1 - pos_mask\n",
    "        \n",
    "        # 低频损失：最大化正相似性\n",
    "        low_loss = -torch.log(\n",
    "            (torch.exp(low_sim) * pos_mask).sum(dim=-1) / \n",
    "            (torch.exp(low_sim).sum(dim=-1) + 1e-8)\n",
    "        ).mean()\n",
    "        \n",
    "        # 高频损失：最小化正相似性\n",
    "        high_loss = torch.log(\n",
    "            (torch.exp(-high_sim) * pos_mask).sum(dim=-1) / \n",
    "            (torch.exp(-high_sim).sum(dim=-1) + 1e-8)\n",
    "        ).mean()\n",
    "        \n",
    "        return low_loss + high_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f505af89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MultiModalWaveletInterestAttention(nn.Module):\n",
    "    '''\n",
    "        Desc: 多模态小波兴趣注意力机制（优化版）\n",
    "            必要性: 当前捕获用户兴趣偏好的方法无法分离用户对物品的Hot兴趣和小众兴趣, 同时融合兴趣的方式是content_embeds + side_embeds\n",
    "            -------------------------------------------\n",
    "            核心改进：\n",
    "                1. 门控融合机制：分别对低频/高频特征设计门控，动态调节content与side特征的贡献比例\n",
    "                2. 注意力显式加权：直接对分离后的低频/高频特征加权，物理意义更明确（低频=热门兴趣，高频=小众兴趣）\n",
    "                3. 对比学习支持：显式输出分离后的低频/高频兴趣特征，便于后续对比损失计算\n",
    "            -------------------------------------------\n",
    "            基于小波变换的多模态兴趣偏好感知, 核心流程：\n",
    "            1. 兴趣分离：对content_embeds、side_embeds、融合特征分别小波分解，得到低频(公共兴趣)和高频(个性化兴趣)分量\n",
    "            2. 门控融合：在低频域用门控加权融合多源特征，高频域用门控增强个性化特征\n",
    "            3. 注意力加权：对融合后的低频/高频特征显式加权，平衡热门与小众兴趣\n",
    "            4. 多尺度重构：通过小波逆变换得到多尺度兴趣感知特征，并保留分离的低/高频兴趣用于对比学习\n",
    "        Args:\n",
    "            content_embeds.shape: torch.Size([B, D])  用户和物品的embedding（B: batch_size, D: embed_dim）\n",
    "            side_embeds.shape: torch.Size([B, D])    多模态融合的embedding\n",
    "        Returns:\n",
    "            mm_interest_prefer_aware_embeds: torch.Size([B, D])  多尺度兴趣感知embedding\n",
    "            low_freq_interest: torch.Size([B, D])  分离后的低频（热门）兴趣特征\n",
    "            high_freq_interest: torch.Size([B, D])  分离后的高频（小众）兴趣特征\n",
    "    '''\n",
    "    def __init__(self, embed_dim, wavelet_name='db4', decomp_level=1):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.wavelet_name = wavelet_name\n",
    "        \n",
    "        # 小波变换与逆变换（支持自动梯度计算）\n",
    "        self.dwt = DWT1DForward(wave=wavelet_name, J=decomp_level)  # 需确保DWT1DForward已正确实现\n",
    "        self.idwt = DWT1DInverse(wave=wavelet_name)                  # 需确保DWT1DInverse已正确实现\n",
    "        \n",
    "        # 改进1：低频/高频门控融合层（动态调节content与side的贡献比例）\n",
    "        self.low_gate = nn.Sequential(\n",
    "            nn.Linear(embed_dim, 1),  # 输出低频融合权重（0-1之间）\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.high_gate = nn.Sequential(\n",
    "            nn.Linear(embed_dim, 1),  # 输出高频融合权重（0-1之间）\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # 改进2：显式注意力机制（直接对低频/高频特征加权）\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim//4),  # 降低维度减少计算量\n",
    "            nn.LayerNorm(embed_dim//4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(embed_dim//4, 2),          # 输出2个权重（低频alpha和高频beta）\n",
    "            nn.Softmax(dim=-1)                   # 确保权重和为1，平衡两种兴趣\n",
    "        )\n",
    "        \n",
    "        # 低频/高频投影层（保持维度一致性）\n",
    "        self.low_proj = nn.Sequential(\n",
    "            nn.Linear(embed_dim//2, embed_dim//2),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.high_proj = nn.Sequential(\n",
    "            nn.Linear(embed_dim//2, embed_dim//2),\n",
    "            nn.BatchNorm1d(embed_dim//2),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        \n",
    "        # 残差归一化\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def wavelet_decomp(self, x):\n",
    "        \"\"\"可微分小波分解（输出低频cA和高频cD分量）\"\"\"\n",
    "        x = x.unsqueeze(1)  # [B, 1, D]  增加通道维度（适应小波变换输入要求）\n",
    "        cA, cD = self.dwt(x)  # cA: [B, 1, D/2], cD: list([B, 1, D/2])（层数=decomp_level）\n",
    "        return cA.squeeze(1), cD[0].squeeze(1)  # 移除通道维度 -> [B, D/2]\n",
    "\n",
    "    def wavelet_recon(self, cA, cD):\n",
    "        \"\"\"可微分小波重构（从低频cA和高频cD恢复原始维度）\"\"\"\n",
    "        cA = cA.unsqueeze(1)  # [B, 1, D/2] 恢复通道维度\n",
    "        cD = [cD.unsqueeze(1)]  # 包装为列表（适应逆变换输入要求）\n",
    "        return self.idwt((cA, cD)).squeeze(1)  # 重构后移除通道维度 -> [B, D]\n",
    "\n",
    "    def forward(self, content_embeds, side_embeds):\n",
    "        '''\n",
    "        content_embeds.shape: torch.Size([B, 64])  用户和物品的embedding\n",
    "        side_embeds.shape: torch.Size([B, 64])    多模态融合的embedding\n",
    "        '''\n",
    "        # ------------------------ 步骤1：多源特征小波分解 ------------------------\n",
    "        # 分解content特征（用户-物品交互信息）\n",
    "        content_cA, content_cD = self.wavelet_decomp(content_embeds)  # [B, 32], [B, 32]\n",
    "        # 分解side特征（多模态辅助信息）\n",
    "        side_cA, side_cD = self.wavelet_decomp(side_embeds)          # [B, 32], [B, 32]\n",
    "        # 分解原始融合特征（content + side的初始融合）\n",
    "        fusion_embeds = content_embeds + side_embeds\n",
    "        fusion_cA, fusion_cD = self.wavelet_decomp(fusion_embeds)    # [B, 32], [B, 32]\n",
    "\n",
    "        # ------------------------ 步骤2：门控融合低频/高频特征 ------------------------\n",
    "        # 低频（热门兴趣）融合：门控加权content_cA、side_cA、fusion_cA\n",
    "        # 门控输入：原始融合特征（包含全局信息）\n",
    "        low_gate_weight = self.low_gate(fusion_embeds)  # [B, 1]  权重范围[0,1]\n",
    "        low_fused = (\n",
    "            low_gate_weight * (content_cA + side_cA) +  # 门控加权content与side的低频分量\n",
    "            (1 - low_gate_weight) * fusion_cA            # 保留原始融合低频分量\n",
    "        )\n",
    "        low_fused = self.low_proj(low_fused)  # 投影层增强特征表达\n",
    "\n",
    "        # 高频（小众兴趣）融合：门控增强个性化特征（content_cD与side_cD的逐元素乘积+融合高频）\n",
    "        high_gate_weight = self.high_gate(fusion_embeds)  # [B, 1]  权重范围[0,1]\n",
    "        high_fused = (\n",
    "            high_gate_weight * (content_cD * side_cD) +   # 逐元素乘积增强个性化（仅保留共同高频特征）\n",
    "            (1 - high_gate_weight) * fusion_cD            # 保留原始融合高频分量\n",
    "        )\n",
    "        high_fused = self.high_proj(high_fused)  # 投影层增强特征表达\n",
    "\n",
    "        # ------------------------ 步骤3：注意力显式加权低频/高频 ------------------------\n",
    "        # 拼接低频/高频特征作为注意力输入（显式关联两种兴趣）\n",
    "        attn_input = torch.cat([low_fused, high_fused], dim=-1)  # [B, 64]\n",
    "        alpha, beta = self.attention(attn_input).chunk(2, dim=-1)  # [B, 1], [B, 1]  注意力权重\n",
    "\n",
    "        # 加权融合并重构多尺度兴趣特征\n",
    "        weighted_low = alpha * low_fused  # 注意力加权后的低频兴趣\n",
    "        weighted_high = beta * high_fused  # 注意力加权后的高频兴趣\n",
    "        mm_interest_prefer_aware_embeds = self.wavelet_recon(weighted_low, weighted_high)  # [B, 64]\n",
    "\n",
    "        # ------------------------ 步骤4：输出分离的低/高频兴趣（用于对比学习） ------------------------\n",
    "        # 低频兴趣：仅用content与side的低频分量重构（纯公共兴趣）\n",
    "        low_freq_interest = self.wavelet_recon(content_cA, side_cA)  # [B, 64]\n",
    "        # 高频兴趣：仅用content的高频分量与融合高频分量重构（纯个性化兴趣）\n",
    "        high_freq_interest = self.wavelet_recon(content_cD, fusion_cD)  # [B, 64]\n",
    "\n",
    "        # 残差连接+归一化（增强训练稳定性）\n",
    "        mm_interest_prefer_aware_embeds = self.norm(mm_interest_prefer_aware_embeds + fusion_embeds)\n",
    "\n",
    "        return mm_interest_prefer_aware_embeds, low_freq_interest, high_freq_interest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a24708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c887532a",
   "metadata": {},
   "source": [
    "# 新增兴趣Switcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69481cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiModalWaveletInterestAttention(nn.Module):\n",
    "    '''\n",
    "        Desc: 多模态小波兴趣注意力机制\n",
    "            必要性:当前捕获用户兴趣偏好的方法无法分离用户对物品的Hot兴趣和小众兴趣,  同时融合兴趣的方式是content_embeds + side_embeds\n",
    "            -------------------------------------------\n",
    "            优点：\n",
    "                小波变换能有效分离频域特征，适合兴趣分解\n",
    "                低频/高频的区分符合热门/小众兴趣的特性\n",
    "                Attention加权可以动态平衡两种兴趣\n",
    "            -------------------------------------------\n",
    "            基于小波变换的，多模态兴趣偏好感知, 初步思路是：\n",
    "            1. 兴趣分离:分别对content_embeds和fusion_embeds以及融合兴趣(content_embeds + side_embeds)进行小波分解，分离出在低频(对多模态公共兴趣，热门兴趣)和高频特征(个性化兴趣，小众兴趣)中进行用户兴趣。\n",
    "            2. 分别在低频和高频域进行content_embeds和 side_embeds进行兴趣偏好融合，目前使用的是element-wise add,用简单高效优雅的方式(还有哪些方式)。\n",
    "            然后，将融合后的低频特征(热门兴趣) 和 高频特征(小众兴趣) 设计一个attention进行加权\n",
    "            3. 多尺度兴趣感知:最后再小波逆变换，得到多尺度用户兴趣感知embeeding 以及高频兴趣和低频兴趣(用于对比学习)\n",
    "        Args:\n",
    "            content_embeds.shape: torch.Size([26495, 64])  用户和物品的embedding\n",
    "            side_embeds.shape: torch.Size([26495, 64])    多模态融合的embeeding\n",
    "        Returns:\n",
    "            mm_interest_prefer_aware_embeds: torch.Size([26495, 64]) ，低频注意力兴趣 torch.Size([26495, 64]) ，高频注意力兴趣 torch.Size([26495, 64]) \n",
    "    '''\n",
    "    def __init__(self, embed_dim, wavelet_name='db1', decomp_level=1):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.wavelet_name = wavelet_name\n",
    "        \n",
    "        # 小波变换与逆变换（支持自动梯度计算）\n",
    "        self.dwt = DWT1DForward(wave=wavelet_name, J=decomp_level)\n",
    "        self.idwt = DWT1DInverse(wave=wavelet_name)\n",
    "        \n",
    "        # 增强的注意力机制\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim//8),\n",
    "            nn.GELU(),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "        \n",
    "        # 低频融合投影层\n",
    "        self.low_fusion = nn.Sequential(\n",
    "            nn.Linear(embed_dim//2 , embed_dim//2),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        \n",
    "        # 高频融合投影层\n",
    "        self.high_fusion = nn.Sequential(\n",
    "            nn.Linear(embed_dim//2 , embed_dim//2),\n",
    "            nn.BatchNorm1d(embed_dim//2),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        \n",
    "        # 残差归一化\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        # 新增：低频门控（调节content/side/fusion的低频贡献）\n",
    "        self.low_gate = nn.Sequential(\n",
    "            nn.Linear( embed_dim//2 * 3 , 3),  # 3个输入源（content/side/fusion）的低频权重\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "        # 新增：高频门控（调节content/side/fusion的高频贡献）\n",
    "        self.high_gate = nn.Sequential(\n",
    "            nn.Linear( embed_dim//2 * 3, 3),  # 3个输入源的高频权重\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "    def wavelet_decomp(self, x):\n",
    "        \"\"\"可微分小波分解\"\"\"\n",
    "        x = x.unsqueeze(1)  # [B,1,D]\n",
    "        cA, cD = self.dwt(x)\n",
    "        return cA.squeeze(1), cD[0].squeeze(1)\n",
    "    \n",
    "    def wavelet_recon(self, cA, cD):\n",
    "        \"\"\"可微分小波重构\"\"\"\n",
    "        cA = cA.unsqueeze(1)\n",
    "        cD = [cD.unsqueeze(1)]\n",
    "        return self.idwt((cA, cD)).squeeze(1)\n",
    "    \n",
    "    def forward(self, content_embeds, side_embeds):\n",
    "        '''\n",
    "        content_embeds.shape: torch.Size([26495, 64])  用户和物品的embedding\n",
    "        side_embeds.shape: torch.Size([26495, 64])    多模态融合的embeeding\n",
    "        '''\n",
    "        # 多尺度小波兴趣分解\n",
    "        content_cA, content_cD = self.wavelet_decomp(content_embeds) # 用户与物品信息 # \n",
    "        side_cA, side_cD = self.wavelet_decomp(side_embeds) # 多模态辅助信息\n",
    "        fusion_cA, fusion_cD  = self.wavelet_decomp(content_embeds + side_embeds) # 融合信息\n",
    "        #print(\"content_cA.shape:\", content_cA.shape, \"content_cD.shape:\", content_cD.shape, \"fusion_cA.shape:\", fusion_cA.shape, \"fusion_cD.shape:\", fusion_cD.shape)\n",
    "        \n",
    "        # 低频、高频兴趣融合\n",
    "        # 低频：\n",
    "        # low_fused = (content_cA + side_cA + fusion_cA) / 3\n",
    "        # ------------------------ 低频门控融合 ------------------------\n",
    "        # 拼接3个低频源特征 [B, 3*(D/2)]\n",
    "        low_sources = torch.cat([content_cA, side_cA, fusion_cA], dim=-1) #96\n",
    "        # print(\"low_sources:\", low_sources.shape) \n",
    "        # 计算门控权重 [B, 3]\n",
    "        low_weights = self.low_gate(low_sources)\n",
    "        # print(\"low_weights:\", low_weights.shape) \n",
    "        # 按权重融合（自动广播）\n",
    "        print(\"low_weights[:, 1] :\", low_weights[:, 1] )\n",
    "        low_fused = (\n",
    "            low_weights[:, 0] * content_cA + low_weights[:, 1] * side_cA + low_weights[:, -1] * fusion_cA\n",
    "        )\n",
    "        print(\"low_fused.shape:\", low_fused.shape)\n",
    "        low_fused = self.low_fusion(low_fused)  # 投影层增强表达\n",
    "        print(\"low_fused.shape:\", low_fused.shape)\n",
    "        # 高频：\n",
    "        # high_fused = (content_cD + side_cD + fusion_cD) / 3\n",
    "        # ------------------------ 高频门控融合 ------------------------\n",
    "        # 拼接3个高频源特征 [B, 3*(D/2)]\n",
    "        high_sources = torch.cat([content_cD, side_cD, fusion_cD], dim=-1)\n",
    "        # 计算门控权重 [B, 3]\n",
    "        high_weights = self.high_gate(high_sources)\n",
    "        # 按权重融合（自动广播）\n",
    "        high_fused = (\n",
    "            high_weights[:, 0:1] * content_cD +\n",
    "            high_weights[:, 1:2] * side_cD +\n",
    "            high_weights[:, 2:-1] * fusion_cD\n",
    "        )\n",
    "        high_fused = self.high_fusion(high_fused)  # 投影层增强表达\n",
    "        #print(\"high_fused.shape\")\n",
    "\n",
    "        \n",
    "        # 原始融合兴趣特征\n",
    "        combined = content_embeds + side_embeds\n",
    "        # combined = torch.multiply(content_embeds, fusion_embeds)\n",
    "        # combined = fusion_embeds\n",
    "        weights = self.attention(torch.concat([low_fused, high_fused], dim=-1))\n",
    "        #weights = self.attention(combined)\n",
    "        \n",
    "        # 加权融合\n",
    "        reconstructed = self.wavelet_recon(\n",
    "            weights[:, 0:1] * low_fused,\n",
    "            weights[:, 1:2] * high_fused\n",
    "        )\n",
    "        # reconstructed = self.wavelet_recon(\n",
    "        #     low_fused,\n",
    "        #     high_fused\n",
    "        # )\n",
    "        low_freq_interest = self.wavelet_recon(low_fused, fusion_cA)\n",
    "        high_freq_interest = self.wavelet_recon(high_fused, fusion_cD)\n",
    "\n",
    "        return reconstructed, low_freq_interest, high_freq_interest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4e15579f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low_weights[:, 0:1] tensor([[0.5164],\n",
      "        [0.3512],\n",
      "        [0.3620],\n",
      "        [0.2356],\n",
      "        [0.2120],\n",
      "        [0.5422],\n",
      "        [0.6239],\n",
      "        [0.4749],\n",
      "        [0.4597],\n",
      "        [0.4543],\n",
      "        [0.1630],\n",
      "        [0.2754],\n",
      "        [0.3663],\n",
      "        [0.3108],\n",
      "        [0.2300],\n",
      "        [0.2014],\n",
      "        [0.2407],\n",
      "        [0.4778],\n",
      "        [0.5756],\n",
      "        [0.3742],\n",
      "        [0.2428],\n",
      "        [0.5289],\n",
      "        [0.0832],\n",
      "        [0.2360],\n",
      "        [0.4012],\n",
      "        [0.1926],\n",
      "        [0.5883],\n",
      "        [0.1996],\n",
      "        [0.6465],\n",
      "        [0.4059],\n",
      "        [0.2878],\n",
      "        [0.6077],\n",
      "        [0.4504],\n",
      "        [0.8166],\n",
      "        [0.3190],\n",
      "        [0.3524],\n",
      "        [0.2123],\n",
      "        [0.2737],\n",
      "        [0.0791],\n",
      "        [0.5854],\n",
      "        [0.2888],\n",
      "        [0.2015],\n",
      "        [0.2088],\n",
      "        [0.3559],\n",
      "        [0.1591],\n",
      "        [0.2684],\n",
      "        [0.2341],\n",
      "        [0.3270],\n",
      "        [0.1925],\n",
      "        [0.5931],\n",
      "        [0.3827],\n",
      "        [0.1824],\n",
      "        [0.2978],\n",
      "        [0.5150],\n",
      "        [0.3679],\n",
      "        [0.3417],\n",
      "        [0.3812],\n",
      "        [0.3635],\n",
      "        [0.2590],\n",
      "        [0.3443],\n",
      "        [0.0392],\n",
      "        [0.5833],\n",
      "        [0.1444],\n",
      "        [0.2293],\n",
      "        [0.2357],\n",
      "        [0.2148],\n",
      "        [0.4220],\n",
      "        [0.2910],\n",
      "        [0.2360],\n",
      "        [0.1748],\n",
      "        [0.3844],\n",
      "        [0.1707],\n",
      "        [0.0766],\n",
      "        [0.3201],\n",
      "        [0.0816],\n",
      "        [0.2184],\n",
      "        [0.3260],\n",
      "        [0.1673],\n",
      "        [0.6481],\n",
      "        [0.1875],\n",
      "        [0.5359],\n",
      "        [0.4344],\n",
      "        [0.1990],\n",
      "        [0.2815],\n",
      "        [0.5006],\n",
      "        [0.5255],\n",
      "        [0.2499],\n",
      "        [0.3951],\n",
      "        [0.1109],\n",
      "        [0.4284],\n",
      "        [0.1710],\n",
      "        [0.3710],\n",
      "        [0.3493],\n",
      "        [0.4533],\n",
      "        [0.2718],\n",
      "        [0.2319],\n",
      "        [0.1712],\n",
      "        [0.1800],\n",
      "        [0.4109],\n",
      "        [0.2162],\n",
      "        [0.0933],\n",
      "        [0.4796],\n",
      "        [0.4351],\n",
      "        [0.1218],\n",
      "        [0.3112],\n",
      "        [0.1364],\n",
      "        [0.1658],\n",
      "        [0.4092],\n",
      "        [0.3719],\n",
      "        [0.2120],\n",
      "        [0.4729],\n",
      "        [0.5072],\n",
      "        [0.2845],\n",
      "        [0.1987],\n",
      "        [0.4257],\n",
      "        [0.1997],\n",
      "        [0.2293],\n",
      "        [0.4007],\n",
      "        [0.3233],\n",
      "        [0.0862],\n",
      "        [0.2072],\n",
      "        [0.3053],\n",
      "        [0.5080],\n",
      "        [0.0694],\n",
      "        [0.6311],\n",
      "        [0.1375],\n",
      "        [0.4263],\n",
      "        [0.3933],\n",
      "        [0.4288],\n",
      "        [0.4337],\n",
      "        [0.7276],\n",
      "        [0.3840],\n",
      "        [0.4083],\n",
      "        [0.3665],\n",
      "        [0.3610],\n",
      "        [0.3966],\n",
      "        [0.1245],\n",
      "        [0.6500],\n",
      "        [0.1100],\n",
      "        [0.3342],\n",
      "        [0.4991],\n",
      "        [0.1792],\n",
      "        [0.3716],\n",
      "        [0.5157],\n",
      "        [0.4370],\n",
      "        [0.4953],\n",
      "        [0.6910],\n",
      "        [0.6329],\n",
      "        [0.1146],\n",
      "        [0.3717],\n",
      "        [0.7650],\n",
      "        [0.4475],\n",
      "        [0.1676],\n",
      "        [0.0604],\n",
      "        [0.2800],\n",
      "        [0.4544],\n",
      "        [0.4291],\n",
      "        [0.2766],\n",
      "        [0.2301],\n",
      "        [0.4499],\n",
      "        [0.2363],\n",
      "        [0.6063],\n",
      "        [0.3802],\n",
      "        [0.2075],\n",
      "        [0.4298],\n",
      "        [0.3922],\n",
      "        [0.2690],\n",
      "        [0.3550],\n",
      "        [0.4888],\n",
      "        [0.5616],\n",
      "        [0.5305],\n",
      "        [0.4974],\n",
      "        [0.6652],\n",
      "        [0.2049],\n",
      "        [0.0730],\n",
      "        [0.1654],\n",
      "        [0.4583],\n",
      "        [0.0416],\n",
      "        [0.1141],\n",
      "        [0.3740],\n",
      "        [0.4826],\n",
      "        [0.1475],\n",
      "        [0.1724],\n",
      "        [0.7501],\n",
      "        [0.4641],\n",
      "        [0.6547],\n",
      "        [0.2210],\n",
      "        [0.3010],\n",
      "        [0.3081],\n",
      "        [0.4380],\n",
      "        [0.4004],\n",
      "        [0.2599],\n",
      "        [0.4629],\n",
      "        [0.3229],\n",
      "        [0.2482],\n",
      "        [0.2981],\n",
      "        [0.2779],\n",
      "        [0.4941],\n",
      "        [0.3386],\n",
      "        [0.3539],\n",
      "        [0.2152],\n",
      "        [0.3282],\n",
      "        [0.3501],\n",
      "        [0.0487],\n",
      "        [0.1449],\n",
      "        [0.0985],\n",
      "        [0.0611],\n",
      "        [0.3344],\n",
      "        [0.0908],\n",
      "        [0.1669],\n",
      "        [0.2057],\n",
      "        [0.5535],\n",
      "        [0.4781],\n",
      "        [0.1790],\n",
      "        [0.1025],\n",
      "        [0.0830],\n",
      "        [0.5033],\n",
      "        [0.2483],\n",
      "        [0.1632],\n",
      "        [0.3378],\n",
      "        [0.5184],\n",
      "        [0.0679],\n",
      "        [0.2930],\n",
      "        [0.2735],\n",
      "        [0.4445],\n",
      "        [0.2620],\n",
      "        [0.3543],\n",
      "        [0.1640],\n",
      "        [0.6344],\n",
      "        [0.3470],\n",
      "        [0.3161],\n",
      "        [0.1894],\n",
      "        [0.1422],\n",
      "        [0.4010],\n",
      "        [0.5935],\n",
      "        [0.3059],\n",
      "        [0.1354],\n",
      "        [0.0802],\n",
      "        [0.5696],\n",
      "        [0.3845],\n",
      "        [0.2049],\n",
      "        [0.2139],\n",
      "        [0.2787],\n",
      "        [0.1326],\n",
      "        [0.1151],\n",
      "        [0.2644],\n",
      "        [0.3889],\n",
      "        [0.5099],\n",
      "        [0.4891],\n",
      "        [0.7750],\n",
      "        [0.4676],\n",
      "        [0.3964],\n",
      "        [0.2812],\n",
      "        [0.0528],\n",
      "        [0.4853],\n",
      "        [0.0941],\n",
      "        [0.5516],\n",
      "        [0.2641],\n",
      "        [0.1284],\n",
      "        [0.1794],\n",
      "        [0.1366],\n",
      "        [0.5153],\n",
      "        [0.1370],\n",
      "        [0.1087],\n",
      "        [0.0858],\n",
      "        [0.1565],\n",
      "        [0.1617],\n",
      "        [0.4742],\n",
      "        [0.5411],\n",
      "        [0.5520],\n",
      "        [0.4666],\n",
      "        [0.2535],\n",
      "        [0.2446],\n",
      "        [0.1421],\n",
      "        [0.2120],\n",
      "        [0.7536],\n",
      "        [0.2388],\n",
      "        [0.2736],\n",
      "        [0.3397],\n",
      "        [0.1648],\n",
      "        [0.4771],\n",
      "        [0.0921],\n",
      "        [0.4452],\n",
      "        [0.1552],\n",
      "        [0.2363],\n",
      "        [0.2762],\n",
      "        [0.2260],\n",
      "        [0.2995],\n",
      "        [0.1548],\n",
      "        [0.1395],\n",
      "        [0.6386],\n",
      "        [0.2864],\n",
      "        [0.1280],\n",
      "        [0.2865],\n",
      "        [0.2768],\n",
      "        [0.1399],\n",
      "        [0.1064],\n",
      "        [0.1726],\n",
      "        [0.2444],\n",
      "        [0.1362],\n",
      "        [0.4217],\n",
      "        [0.4727],\n",
      "        [0.4579],\n",
      "        [0.1721],\n",
      "        [0.4748],\n",
      "        [0.1659],\n",
      "        [0.1269],\n",
      "        [0.2420],\n",
      "        [0.1136],\n",
      "        [0.3505],\n",
      "        [0.2666],\n",
      "        [0.1615],\n",
      "        [0.5623],\n",
      "        [0.3697],\n",
      "        [0.0944],\n",
      "        [0.3883],\n",
      "        [0.1960],\n",
      "        [0.3722],\n",
      "        [0.4797],\n",
      "        [0.5567],\n",
      "        [0.3039],\n",
      "        [0.2934],\n",
      "        [0.1188],\n",
      "        [0.1237],\n",
      "        [0.2386],\n",
      "        [0.0951],\n",
      "        [0.1516],\n",
      "        [0.1349],\n",
      "        [0.3635],\n",
      "        [0.3537],\n",
      "        [0.4168],\n",
      "        [0.4086],\n",
      "        [0.9070],\n",
      "        [0.3989],\n",
      "        [0.2102],\n",
      "        [0.5091],\n",
      "        [0.2498],\n",
      "        [0.3244],\n",
      "        [0.3784],\n",
      "        [0.3941],\n",
      "        [0.2651],\n",
      "        [0.3486],\n",
      "        [0.5521],\n",
      "        [0.1757],\n",
      "        [0.5425],\n",
      "        [0.3089],\n",
      "        [0.2374],\n",
      "        [0.3107],\n",
      "        [0.2280],\n",
      "        [0.0708],\n",
      "        [0.5427],\n",
      "        [0.7144],\n",
      "        [0.4862],\n",
      "        [0.5925],\n",
      "        [0.7244],\n",
      "        [0.4307],\n",
      "        [0.1108],\n",
      "        [0.2897],\n",
      "        [0.3829],\n",
      "        [0.3696],\n",
      "        [0.3239],\n",
      "        [0.6078],\n",
      "        [0.6611],\n",
      "        [0.3531],\n",
      "        [0.5270],\n",
      "        [0.2518],\n",
      "        [0.2353],\n",
      "        [0.3394],\n",
      "        [0.1580],\n",
      "        [0.2111],\n",
      "        [0.1178],\n",
      "        [0.2910],\n",
      "        [0.0963],\n",
      "        [0.4073],\n",
      "        [0.1287],\n",
      "        [0.1941],\n",
      "        [0.4008],\n",
      "        [0.0567],\n",
      "        [0.1709],\n",
      "        [0.2196],\n",
      "        [0.1201],\n",
      "        [0.1467],\n",
      "        [0.4209],\n",
      "        [0.2579],\n",
      "        [0.2961],\n",
      "        [0.3647],\n",
      "        [0.0224],\n",
      "        [0.5097],\n",
      "        [0.0553],\n",
      "        [0.4063],\n",
      "        [0.2507],\n",
      "        [0.3633],\n",
      "        [0.3598],\n",
      "        [0.4924],\n",
      "        [0.3432],\n",
      "        [0.3884],\n",
      "        [0.1025],\n",
      "        [0.3240],\n",
      "        [0.3498],\n",
      "        [0.3172],\n",
      "        [0.4058],\n",
      "        [0.1509],\n",
      "        [0.3690],\n",
      "        [0.3304],\n",
      "        [0.0811],\n",
      "        [0.1767],\n",
      "        [0.1448],\n",
      "        [0.2256],\n",
      "        [0.1684],\n",
      "        [0.1812],\n",
      "        [0.2973],\n",
      "        [0.4858],\n",
      "        [0.1516],\n",
      "        [0.3864],\n",
      "        [0.2045],\n",
      "        [0.3416],\n",
      "        [0.0947],\n",
      "        [0.1198],\n",
      "        [0.0922],\n",
      "        [0.3235],\n",
      "        [0.2141],\n",
      "        [0.4360],\n",
      "        [0.2070],\n",
      "        [0.0769],\n",
      "        [0.6020],\n",
      "        [0.2613],\n",
      "        [0.7120],\n",
      "        [0.2724],\n",
      "        [0.1787],\n",
      "        [0.2995],\n",
      "        [0.4808],\n",
      "        [0.2514],\n",
      "        [0.1792],\n",
      "        [0.5221],\n",
      "        [0.3673],\n",
      "        [0.2645],\n",
      "        [0.0946],\n",
      "        [0.2371],\n",
      "        [0.4605],\n",
      "        [0.2101],\n",
      "        [0.7262],\n",
      "        [0.2936],\n",
      "        [0.3805],\n",
      "        [0.5664],\n",
      "        [0.1974],\n",
      "        [0.4412],\n",
      "        [0.6047],\n",
      "        [0.4695],\n",
      "        [0.0488],\n",
      "        [0.2530],\n",
      "        [0.2750],\n",
      "        [0.1870],\n",
      "        [0.2563],\n",
      "        [0.4304],\n",
      "        [0.1022],\n",
      "        [0.3249],\n",
      "        [0.1636],\n",
      "        [0.4595],\n",
      "        [0.2211],\n",
      "        [0.6542],\n",
      "        [0.5827],\n",
      "        [0.5165],\n",
      "        [0.6671],\n",
      "        [0.5465],\n",
      "        [0.3540],\n",
      "        [0.4257],\n",
      "        [0.1995],\n",
      "        [0.2435],\n",
      "        [0.2320],\n",
      "        [0.2059],\n",
      "        [0.3118],\n",
      "        [0.1067],\n",
      "        [0.3571],\n",
      "        [0.4820],\n",
      "        [0.1924],\n",
      "        [0.4429],\n",
      "        [0.3889],\n",
      "        [0.5181],\n",
      "        [0.0880],\n",
      "        [0.2960],\n",
      "        [0.0778],\n",
      "        [0.1419],\n",
      "        [0.3389],\n",
      "        [0.4024],\n",
      "        [0.2981],\n",
      "        [0.3228],\n",
      "        [0.1679],\n",
      "        [0.2704],\n",
      "        [0.5398],\n",
      "        [0.7448],\n",
      "        [0.3564],\n",
      "        [0.1055],\n",
      "        [0.3274],\n",
      "        [0.4439],\n",
      "        [0.1972],\n",
      "        [0.0700],\n",
      "        [0.1764],\n",
      "        [0.3642],\n",
      "        [0.2687],\n",
      "        [0.2292],\n",
      "        [0.4373],\n",
      "        [0.0918],\n",
      "        [0.6684],\n",
      "        [0.5162],\n",
      "        [0.2392],\n",
      "        [0.2491],\n",
      "        [0.1510],\n",
      "        [0.4869],\n",
      "        [0.4654],\n",
      "        [0.7535],\n",
      "        [0.2551],\n",
      "        [0.6114]], grad_fn=<SliceBackward0>)\n",
      "low_weights[:, 1:2] : tensor([[0.2908],\n",
      "        [0.4653],\n",
      "        [0.3408],\n",
      "        [0.5105],\n",
      "        [0.4920],\n",
      "        [0.2041],\n",
      "        [0.0831],\n",
      "        [0.3951],\n",
      "        [0.2661],\n",
      "        [0.3342],\n",
      "        [0.1243],\n",
      "        [0.2757],\n",
      "        [0.5539],\n",
      "        [0.4088],\n",
      "        [0.4589],\n",
      "        [0.3912],\n",
      "        [0.4154],\n",
      "        [0.3216],\n",
      "        [0.2508],\n",
      "        [0.3976],\n",
      "        [0.1488],\n",
      "        [0.3172],\n",
      "        [0.6127],\n",
      "        [0.4517],\n",
      "        [0.3003],\n",
      "        [0.6629],\n",
      "        [0.2522],\n",
      "        [0.6066],\n",
      "        [0.2489],\n",
      "        [0.3887],\n",
      "        [0.4975],\n",
      "        [0.0861],\n",
      "        [0.2089],\n",
      "        [0.1073],\n",
      "        [0.4292],\n",
      "        [0.2545],\n",
      "        [0.2282],\n",
      "        [0.5898],\n",
      "        [0.3722],\n",
      "        [0.2070],\n",
      "        [0.1508],\n",
      "        [0.7161],\n",
      "        [0.1368],\n",
      "        [0.1875],\n",
      "        [0.3446],\n",
      "        [0.5005],\n",
      "        [0.3260],\n",
      "        [0.1774],\n",
      "        [0.3690],\n",
      "        [0.1529],\n",
      "        [0.3633],\n",
      "        [0.4805],\n",
      "        [0.3824],\n",
      "        [0.1318],\n",
      "        [0.3882],\n",
      "        [0.3752],\n",
      "        [0.5082],\n",
      "        [0.3349],\n",
      "        [0.2265],\n",
      "        [0.3587],\n",
      "        [0.7843],\n",
      "        [0.2188],\n",
      "        [0.2149],\n",
      "        [0.6264],\n",
      "        [0.4573],\n",
      "        [0.3293],\n",
      "        [0.0804],\n",
      "        [0.3542],\n",
      "        [0.0825],\n",
      "        [0.2448],\n",
      "        [0.2638],\n",
      "        [0.5353],\n",
      "        [0.1851],\n",
      "        [0.5410],\n",
      "        [0.5926],\n",
      "        [0.4706],\n",
      "        [0.1638],\n",
      "        [0.5498],\n",
      "        [0.2158],\n",
      "        [0.5956],\n",
      "        [0.0804],\n",
      "        [0.4189],\n",
      "        [0.2507],\n",
      "        [0.1255],\n",
      "        [0.2217],\n",
      "        [0.2514],\n",
      "        [0.5764],\n",
      "        [0.5378],\n",
      "        [0.4976],\n",
      "        [0.3904],\n",
      "        [0.2354],\n",
      "        [0.0981],\n",
      "        [0.4665],\n",
      "        [0.1631],\n",
      "        [0.4318],\n",
      "        [0.6848],\n",
      "        [0.7595],\n",
      "        [0.4658],\n",
      "        [0.3652],\n",
      "        [0.1658],\n",
      "        [0.2292],\n",
      "        [0.4299],\n",
      "        [0.2837],\n",
      "        [0.6609],\n",
      "        [0.3936],\n",
      "        [0.2961],\n",
      "        [0.6339],\n",
      "        [0.2053],\n",
      "        [0.3802],\n",
      "        [0.5974],\n",
      "        [0.2749],\n",
      "        [0.2898],\n",
      "        [0.2289],\n",
      "        [0.3989],\n",
      "        [0.2837],\n",
      "        [0.5148],\n",
      "        [0.3576],\n",
      "        [0.2864],\n",
      "        [0.2235],\n",
      "        [0.7381],\n",
      "        [0.4945],\n",
      "        [0.2251],\n",
      "        [0.1621],\n",
      "        [0.8499],\n",
      "        [0.0667],\n",
      "        [0.1770],\n",
      "        [0.3031],\n",
      "        [0.3875],\n",
      "        [0.2258],\n",
      "        [0.4147],\n",
      "        [0.1810],\n",
      "        [0.5169],\n",
      "        [0.2993],\n",
      "        [0.3015],\n",
      "        [0.3026],\n",
      "        [0.4315],\n",
      "        [0.4776],\n",
      "        [0.1232],\n",
      "        [0.4608],\n",
      "        [0.3259],\n",
      "        [0.3815],\n",
      "        [0.6229],\n",
      "        [0.1987],\n",
      "        [0.2589],\n",
      "        [0.4156],\n",
      "        [0.3909],\n",
      "        [0.2025],\n",
      "        [0.1923],\n",
      "        [0.3977],\n",
      "        [0.3676],\n",
      "        [0.0430],\n",
      "        [0.2082],\n",
      "        [0.3319],\n",
      "        [0.8890],\n",
      "        [0.3484],\n",
      "        [0.3673],\n",
      "        [0.1687],\n",
      "        [0.5142],\n",
      "        [0.4404],\n",
      "        [0.1439],\n",
      "        [0.5997],\n",
      "        [0.2233],\n",
      "        [0.2818],\n",
      "        [0.3859],\n",
      "        [0.3739],\n",
      "        [0.4149],\n",
      "        [0.5145],\n",
      "        [0.3158],\n",
      "        [0.2212],\n",
      "        [0.3013],\n",
      "        [0.2608],\n",
      "        [0.2498],\n",
      "        [0.1554],\n",
      "        [0.2958],\n",
      "        [0.6945],\n",
      "        [0.4419],\n",
      "        [0.2690],\n",
      "        [0.4670],\n",
      "        [0.1229],\n",
      "        [0.4497],\n",
      "        [0.1929],\n",
      "        [0.4840],\n",
      "        [0.2398],\n",
      "        [0.0971],\n",
      "        [0.2316],\n",
      "        [0.2092],\n",
      "        [0.6153],\n",
      "        [0.6648],\n",
      "        [0.2900],\n",
      "        [0.3244],\n",
      "        [0.2964],\n",
      "        [0.4121],\n",
      "        [0.2706],\n",
      "        [0.4883],\n",
      "        [0.4492],\n",
      "        [0.2965],\n",
      "        [0.1755],\n",
      "        [0.3577],\n",
      "        [0.4714],\n",
      "        [0.1260],\n",
      "        [0.3830],\n",
      "        [0.3462],\n",
      "        [0.0850],\n",
      "        [0.7691],\n",
      "        [0.6099],\n",
      "        [0.3778],\n",
      "        [0.5190],\n",
      "        [0.4402],\n",
      "        [0.6648],\n",
      "        [0.4214],\n",
      "        [0.5186],\n",
      "        [0.1693],\n",
      "        [0.1196],\n",
      "        [0.5583],\n",
      "        [0.4348],\n",
      "        [0.6451],\n",
      "        [0.2663],\n",
      "        [0.6078],\n",
      "        [0.0768],\n",
      "        [0.3741],\n",
      "        [0.0859],\n",
      "        [0.7398],\n",
      "        [0.3647],\n",
      "        [0.4068],\n",
      "        [0.2338],\n",
      "        [0.3293],\n",
      "        [0.1540],\n",
      "        [0.1817],\n",
      "        [0.1010],\n",
      "        [0.2720],\n",
      "        [0.2400],\n",
      "        [0.6735],\n",
      "        [0.3744],\n",
      "        [0.3388],\n",
      "        [0.2630],\n",
      "        [0.1624],\n",
      "        [0.4386],\n",
      "        [0.4357],\n",
      "        [0.2386],\n",
      "        [0.0899],\n",
      "        [0.5545],\n",
      "        [0.3692],\n",
      "        [0.2330],\n",
      "        [0.5526],\n",
      "        [0.6265],\n",
      "        [0.4287],\n",
      "        [0.1738],\n",
      "        [0.1906],\n",
      "        [0.1101],\n",
      "        [0.1614],\n",
      "        [0.1209],\n",
      "        [0.2145],\n",
      "        [0.2760],\n",
      "        [0.8548],\n",
      "        [0.3445],\n",
      "        [0.6725],\n",
      "        [0.2376],\n",
      "        [0.5068],\n",
      "        [0.3463],\n",
      "        [0.5753],\n",
      "        [0.7019],\n",
      "        [0.2336],\n",
      "        [0.5905],\n",
      "        [0.4633],\n",
      "        [0.6268],\n",
      "        [0.0878],\n",
      "        [0.5038],\n",
      "        [0.3444],\n",
      "        [0.1996],\n",
      "        [0.1780],\n",
      "        [0.1912],\n",
      "        [0.6284],\n",
      "        [0.1552],\n",
      "        [0.3648],\n",
      "        [0.6458],\n",
      "        [0.1863],\n",
      "        [0.2664],\n",
      "        [0.2950],\n",
      "        [0.4760],\n",
      "        [0.3539],\n",
      "        [0.2436],\n",
      "        [0.1604],\n",
      "        [0.0644],\n",
      "        [0.6107],\n",
      "        [0.0647],\n",
      "        [0.2845],\n",
      "        [0.3335],\n",
      "        [0.2272],\n",
      "        [0.6306],\n",
      "        [0.6161],\n",
      "        [0.1975],\n",
      "        [0.1769],\n",
      "        [0.6486],\n",
      "        [0.5771],\n",
      "        [0.2898],\n",
      "        [0.5324],\n",
      "        [0.3166],\n",
      "        [0.5087],\n",
      "        [0.4814],\n",
      "        [0.4130],\n",
      "        [0.2634],\n",
      "        [0.1174],\n",
      "        [0.4730],\n",
      "        [0.1246],\n",
      "        [0.0950],\n",
      "        [0.4582],\n",
      "        [0.5824],\n",
      "        [0.2862],\n",
      "        [0.4027],\n",
      "        [0.4078],\n",
      "        [0.6268],\n",
      "        [0.1717],\n",
      "        [0.1988],\n",
      "        [0.5173],\n",
      "        [0.4581],\n",
      "        [0.2759],\n",
      "        [0.3051],\n",
      "        [0.4468],\n",
      "        [0.1897],\n",
      "        [0.1648],\n",
      "        [0.2693],\n",
      "        [0.4762],\n",
      "        [0.6039],\n",
      "        [0.6491],\n",
      "        [0.5759],\n",
      "        [0.5939],\n",
      "        [0.5974],\n",
      "        [0.5956],\n",
      "        [0.2987],\n",
      "        [0.1341],\n",
      "        [0.4104],\n",
      "        [0.2487],\n",
      "        [0.0626],\n",
      "        [0.2118],\n",
      "        [0.3678],\n",
      "        [0.3006],\n",
      "        [0.5069],\n",
      "        [0.2717],\n",
      "        [0.3111],\n",
      "        [0.3222],\n",
      "        [0.1941],\n",
      "        [0.3781],\n",
      "        [0.1793],\n",
      "        [0.7351],\n",
      "        [0.2924],\n",
      "        [0.2496],\n",
      "        [0.2899],\n",
      "        [0.2236],\n",
      "        [0.4282],\n",
      "        [0.6709],\n",
      "        [0.3354],\n",
      "        [0.2276],\n",
      "        [0.2674],\n",
      "        [0.2116],\n",
      "        [0.2253],\n",
      "        [0.4518],\n",
      "        [0.1089],\n",
      "        [0.4790],\n",
      "        [0.3372],\n",
      "        [0.3257],\n",
      "        [0.2222],\n",
      "        [0.1433],\n",
      "        [0.1720],\n",
      "        [0.4529],\n",
      "        [0.1865],\n",
      "        [0.3098],\n",
      "        [0.4928],\n",
      "        [0.3084],\n",
      "        [0.6289],\n",
      "        [0.6155],\n",
      "        [0.3109],\n",
      "        [0.3679],\n",
      "        [0.1489],\n",
      "        [0.2947],\n",
      "        [0.1519],\n",
      "        [0.6539],\n",
      "        [0.4032],\n",
      "        [0.6368],\n",
      "        [0.3612],\n",
      "        [0.2572],\n",
      "        [0.3618],\n",
      "        [0.4561],\n",
      "        [0.2745],\n",
      "        [0.3847],\n",
      "        [0.4382],\n",
      "        [0.3809],\n",
      "        [0.9256],\n",
      "        [0.3483],\n",
      "        [0.5520],\n",
      "        [0.1173],\n",
      "        [0.2033],\n",
      "        [0.2414],\n",
      "        [0.4448],\n",
      "        [0.1640],\n",
      "        [0.5971],\n",
      "        [0.2201],\n",
      "        [0.4441],\n",
      "        [0.2813],\n",
      "        [0.1008],\n",
      "        [0.1407],\n",
      "        [0.4544],\n",
      "        [0.4178],\n",
      "        [0.2199],\n",
      "        [0.4209],\n",
      "        [0.6077],\n",
      "        [0.2543],\n",
      "        [0.4763],\n",
      "        [0.5815],\n",
      "        [0.3325],\n",
      "        [0.1647],\n",
      "        [0.3761],\n",
      "        [0.1818],\n",
      "        [0.6987],\n",
      "        [0.4380],\n",
      "        [0.7146],\n",
      "        [0.1761],\n",
      "        [0.5815],\n",
      "        [0.3625],\n",
      "        [0.6640],\n",
      "        [0.4131],\n",
      "        [0.1041],\n",
      "        [0.1584],\n",
      "        [0.7374],\n",
      "        [0.8573],\n",
      "        [0.1048],\n",
      "        [0.4892],\n",
      "        [0.0881],\n",
      "        [0.3527],\n",
      "        [0.5685],\n",
      "        [0.5033],\n",
      "        [0.0477],\n",
      "        [0.3577],\n",
      "        [0.3893],\n",
      "        [0.2929],\n",
      "        [0.1401],\n",
      "        [0.1592],\n",
      "        [0.7230],\n",
      "        [0.3727],\n",
      "        [0.2961],\n",
      "        [0.5798],\n",
      "        [0.1723],\n",
      "        [0.1465],\n",
      "        [0.4510],\n",
      "        [0.0405],\n",
      "        [0.7562],\n",
      "        [0.1769],\n",
      "        [0.1133],\n",
      "        [0.1355],\n",
      "        [0.7757],\n",
      "        [0.4700],\n",
      "        [0.2319],\n",
      "        [0.4655],\n",
      "        [0.2955],\n",
      "        [0.2539],\n",
      "        [0.6266],\n",
      "        [0.4621],\n",
      "        [0.7046],\n",
      "        [0.0801],\n",
      "        [0.4823],\n",
      "        [0.1905],\n",
      "        [0.2621],\n",
      "        [0.3031],\n",
      "        [0.1471],\n",
      "        [0.2597],\n",
      "        [0.4919],\n",
      "        [0.1464],\n",
      "        [0.1564],\n",
      "        [0.3571],\n",
      "        [0.5534],\n",
      "        [0.4793],\n",
      "        [0.6447],\n",
      "        [0.1794],\n",
      "        [0.3374],\n",
      "        [0.2363],\n",
      "        [0.1731],\n",
      "        [0.4135],\n",
      "        [0.5030],\n",
      "        [0.3380],\n",
      "        [0.2083],\n",
      "        [0.2661],\n",
      "        [0.2912],\n",
      "        [0.7166],\n",
      "        [0.3152],\n",
      "        [0.1938],\n",
      "        [0.5834],\n",
      "        [0.5225],\n",
      "        [0.7103],\n",
      "        [0.3496],\n",
      "        [0.3657],\n",
      "        [0.1353],\n",
      "        [0.1758],\n",
      "        [0.6653],\n",
      "        [0.2611],\n",
      "        [0.2221],\n",
      "        [0.2617],\n",
      "        [0.5198],\n",
      "        [0.1590],\n",
      "        [0.4032],\n",
      "        [0.5459],\n",
      "        [0.3381],\n",
      "        [0.3003],\n",
      "        [0.6250],\n",
      "        [0.0781],\n",
      "        [0.1289],\n",
      "        [0.6579],\n",
      "        [0.1631],\n",
      "        [0.4362],\n",
      "        [0.2672],\n",
      "        [0.1379],\n",
      "        [0.1906],\n",
      "        [0.4627],\n",
      "        [0.2263]], grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (512) must match the size of tensor b (32) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m content \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m64\u001b[39m)\n\u001b[1;32m      9\u001b[0m side \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m64\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m output, low, high \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mside\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# 输出说明：\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# - output: 融合后的兴趣特征 [512,64]\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# - low: 门控融合后的低频特征（热门兴趣） [512,32]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# 推理模式（无需对比学习）\u001b[39;00m\n\u001b[1;32m     19\u001b[0m output, low, high \u001b[38;5;241m=\u001b[39m model(content, side)\n",
      "File \u001b[0;32m~/miniconda3/envs/orange/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/orange/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[49], line 101\u001b[0m, in \u001b[0;36mMultiModalWaveletInterestAttention.forward\u001b[0;34m(self, content_embeds, side_embeds)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlow_weights[:, 0:1]\u001b[39m\u001b[38;5;124m\"\u001b[39m, low_weights[:, \u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlow_weights[:, 1:2] :\u001b[39m\u001b[38;5;124m\"\u001b[39m, low_weights[:, \u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m2\u001b[39m] )\n\u001b[1;32m    100\u001b[0m low_fused \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 101\u001b[0m     \u001b[43mlow_weights\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcontent_cA\u001b[49m \u001b[38;5;241m+\u001b[39m low_weights[:, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m side_cA \u001b[38;5;241m+\u001b[39m low_weights[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m fusion_cA\n\u001b[1;32m    102\u001b[0m )\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlow_fused.shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, low_fused\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    104\u001b[0m low_fused \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_fusion(low_fused)  \u001b[38;5;66;03m# 投影层增强表达\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (512) must match the size of tensor b (32) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# 初始化模型\n",
    "model = MultiModalWaveletInterestAttention(\n",
    "    embed_dim=64,\n",
    "    wavelet_name='db1'\n",
    ")\n",
    "\n",
    "# 前向传播（训练模式，带对比学习）\n",
    "content = torch.randn(512, 64)\n",
    "side = torch.randn(512, 64)\n",
    "output, low, high = model(content, side)\n",
    "\n",
    "# 输出说明：\n",
    "# - output: 融合后的兴趣特征 [512,64]\n",
    "# - low: 门控融合后的低频特征（热门兴趣） [512,32]\n",
    "# - high: 门控融合后的高频特征（小众兴趣） [512,32]\n",
    "# - loss: 对比学习损失（可用于反向传播）\n",
    "\n",
    "# 推理模式（无需对比学习）\n",
    "output, low, high = model(content, side)\n",
    "print(\"output:\", output, \"low:\", low, \"high:\", high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a553ea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(low_feat, high_feat, temperature=0.1):\n",
    "    \"\"\"改进的对比损失\"\"\"\n",
    "    # 特征归一化\n",
    "    low_norm = F.normalize(low_feat, p=2, dim=1)\n",
    "    high_norm = F.normalize(high_feat, p=2, dim=1)\n",
    "    \n",
    "    # 相似度矩阵\n",
    "    sim_matrix = torch.mm(low_norm, high_norm.T) / temperature\n",
    "    \n",
    "    # 对称式损失\n",
    "    labels = torch.arange(len(low_feat)).to(low_feat.device)\n",
    "    loss = (F.cross_entropy(sim_matrix, labels) + \n",
    "            F.cross_entropy(sim_matrix.T, labels)) / 2\n",
    "    \n",
    "    # 正交正则项\n",
    "    orth_reg = torch.norm(torch.mm(low_norm.T, high_norm)) / len(low_feat)\n",
    "    \n",
    "    return loss + 0.1 * orth_reg  # 总损失\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b580c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def contrastive_loss2( view1, view2, temperature=0.1):\n",
    "    view1, view2 = F.normalize(view1, dim=1), F.normalize(view2, dim=1)\n",
    "    pos_score = (view1 * view2).sum(dim=-1)\n",
    "    pos_score = torch.exp(pos_score / temperature)\n",
    "    ttl_score = torch.matmul(view1, view2.transpose(0, 1))\n",
    "    ttl_score = torch.exp(ttl_score / temperature).sum(dim=1)\n",
    "    cl_loss = -torch.log(pos_score / ttl_score)\n",
    "    return torch.mean(cl_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8bdd9cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.1067)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contrastive_loss(low, high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f743aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.1048)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contrastive_loss2(low, high)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "orange",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
